{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c01ddda-f2e1-4963-8a13-1714bca8e6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CustomLSTM</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">63,360</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CustomLSTM</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">179,840</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CustomLSTM</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">134,880</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1200</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">67,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,736</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ OUT_multivariate_classifier     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">147</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                         │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_0 (\u001b[38;5;33mCustomLSTM\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m120\u001b[0m)        │        \u001b[38;5;34m63,360\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m120\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mCustomLSTM\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m160\u001b[0m)        │       \u001b[38;5;34m179,840\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m160\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mCustomLSTM\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m120\u001b[0m)        │       \u001b[38;5;34m134,880\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m120\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1200\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_0 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)             │        \u001b[38;5;34m67,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)             │         \u001b[38;5;34m2,736\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)             │         \u001b[38;5;34m2,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ OUT_multivariate_classifier     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m147\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)                         │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">450,573</span> (1.72 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m450,573\u001b[0m (1.72 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">450,571</span> (1.72 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m450,571\u001b[0m (1.72 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "class CustomLSTM(LSTM):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        kwargs.pop('time_major', None)  # Remove the 'time_major' argument if it exists\n",
    "        super(CustomLSTM, self).__init__(*args, **kwargs)\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "\n",
    "get_custom_objects().update({'CustomLSTM': CustomLSTM})\n",
    "\n",
    "trained_model = load_model(r\"C:\\Users\\pranali\\Downloads\\5g_classifier.h5\", custom_objects={'LSTM': CustomLSTM})\n",
    "\n",
    "trained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39a2c9bb-36e4-480d-a79c-4e2e8c21fb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "X_test = np.load(r\"C:\\Users\\pranali\\Desktop\\Throughput_prediction\\Mature(1)\\Mature-main\\Datasets\\Testing\\all_data_classifier_test_x.npy\")\n",
    "y_test = np.load(r\"C:\\Users\\pranali\\Desktop\\Throughput_prediction\\Mature(1)\\Mature-main\\Datasets\\Testing\\all_data_classifier_test_y.npy\")\n",
    "\n",
    "# Set seeds\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebe3158f-a4b0-49b8-873a-3b8995fac6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pranali\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pranali\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\pranali\\AppData\\Local\\Temp\\tmpsnrmvzuz\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\pranali\\AppData\\Local\\Temp\\tmpsnrmvzuz\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\pranali\\AppData\\Local\\Temp\\tmpsnrmvzuz'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 10, 11), dtype=tf.float32, name='input_layer')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2174290421392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2174291706128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2174290427152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2174290427344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2174291708816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2174291709008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2174291710544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2174291711504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2174291708624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2174291712656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2174291713616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2174291711888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2174291714960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2174291715344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2174291716496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2174291714192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2174291717648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "\n",
    "#quantized model default\n",
    "\n",
    "# Convert the model to a TensorFlow Lite model with post-training quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(trained_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Enable Select TF ops to support operations not natively supported by TFLite\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, \n",
    "                                       tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "\n",
    "# Disable lowering of tensor list operations, which might be causing the error\n",
    "converter._experimental_lower_tensor_list_ops = False\n",
    "\n",
    "# Enable resource variable support\n",
    "converter.experimental_enable_resource_variables = True\n",
    "\n",
    "# Convert the model\n",
    "tflite_quant_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e22c757f-77bc-4f33-951a-bf904b34abfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the TFLite model\n",
    "with open('5g_classifier_dynamic.tflite', 'wb') as f:\n",
    "    f.write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d07e60f-b463-4acc-8feb-9aad2892bec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the quantized TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path='5g_classifier_dynamic.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get details of input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df5c64ef-03ff-4327-a7f4-05345bd7111f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Inference Time for quantized classifier 5g sample: 7.196525 seconds\n",
      "Avg Inference Time for quantized classifier 5g sample: 0.000957 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Initialize list to store predictions\n",
    "predictions = []\n",
    "\n",
    "# Measure inference time\n",
    "start_time = time.time()\n",
    "for i in range(X_test.shape[0]):\n",
    "    # Prepare the input data (trim the extra dimension if necessary)\n",
    "    input_data = X_test[i]  # Trim to match the expected shape (1, 10, 10)\n",
    "    input_data = np.expand_dims(input_data, axis=0).astype(np.float32)\n",
    "    \n",
    "    # Set the input tensor\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    \n",
    "    # Run inference\n",
    "    interpreter.invoke()\n",
    "    \n",
    "    # Get the output tensor\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    # Append prediction to the list\n",
    "    predictions.append(output_data)\n",
    "\n",
    "end_time = time.time()\n",
    "total_inference_time = end_time - start_time\n",
    "avg_inference_time = total_inference_time / len(X_test)\n",
    "\n",
    "print(f\"Total Inference Time for quantized classifier 5g sample: {total_inference_time:.6f} seconds\")\n",
    "print(f\"Avg Inference Time for quantized classifier 5g sample: {avg_inference_time:.6f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b512bff-8ac5-45fa-ac38-1c84cb7315ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized TFLite model size: 511.02 KB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Get the size of the saved quantized TFLite model\n",
    "model_size = os.path.getsize('5g_classifier_dynamic.tflite')\n",
    "print(f\"Quantized TFLite model size: {model_size / 1024:.2f} KB\")  # Convert to KB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56b28304-de94-48c1-9457-cf92774406c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.062184932657520134\n",
      "Accuracy: 0.8976063829787234\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the quantized TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Function to run inference using the interpreter\n",
    "def run_inference(interpreter, X_test):\n",
    "    predictions = []\n",
    "    for i in range(len(X_test)):\n",
    "        # Preprocess the input as per your model's input requirements\n",
    "        input_data = np.expand_dims(X_test[i], axis=0).astype(np.float32)  # Adjust datatype if needed\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "        interpreter.invoke()\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "        predictions.append(output_data)\n",
    "    return np.array(predictions)\n",
    "\n",
    "# Assume X_test and y_test are your test data and labels\n",
    "# Run inference on the quantized model\n",
    "predictions = run_inference(interpreter, X_test)\n",
    "\n",
    "# Convert predictions to the correct shape if needed (e.g., flattening)\n",
    "predictions = np.squeeze(predictions)\n",
    "\n",
    "# Compute loss (assuming Mean Squared Error for regression, adjust for classification)\n",
    "mse = np.mean(np.square(predictions - y_test))\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "# Compute accuracy (assuming a classifier, adjust if necessary)\n",
    "correct_predictions = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1))\n",
    "accuracy = correct_predictions / len(y_test)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d25d2497-c319-47ac-a55a-4fcc7ceb4e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 270   81   22]\n",
      " [  66  772  448]\n",
      " [  26  127 5708]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Low (0)       0.75      0.72      0.73       373\n",
      "  Medium (1)       0.79      0.60      0.68      1286\n",
      "    High (2)       0.92      0.97      0.95      5861\n",
      "\n",
      "    accuracy                           0.90      7520\n",
      "   macro avg       0.82      0.77      0.79      7520\n",
      "weighted avg       0.89      0.90      0.89      7520\n",
      "\n",
      "Accuracy: 0.8976063829787234\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Load the quantized TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Function to run inference using the interpreter\n",
    "def run_inference(interpreter, X_test):\n",
    "    predictions = []\n",
    "    for i in range(len(X_test)):\n",
    "        # Preprocess the input as per your model's input requirements\n",
    "        input_data = np.expand_dims(X_test[i], axis=0).astype(np.float32)  # Adjust datatype if needed\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "        interpreter.invoke()\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "        predictions.append(output_data)\n",
    "    return np.array(predictions)\n",
    "\n",
    "# Assume X_test and y_test are your test data and labels\n",
    "# Run inference on the quantized model\n",
    "predictions = run_inference(interpreter, X_test)\n",
    "\n",
    "# Convert predictions to the correct shape if needed (e.g., flattening)\n",
    "predictions = np.squeeze(predictions)\n",
    "\n",
    "# For classification, get the predicted class and the true class\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print the confusion matrix\n",
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Print the classification report\n",
    "target_names = [\"Low (0)\", \"Medium (1)\", \"High (2)\"]\n",
    "class_report = classification_report(true_classes, predicted_classes, target_names=target_names)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Optional: If you need to compute accuracy again\n",
    "accuracy = np.sum(predicted_classes == true_classes) / len(true_classes)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e65a47-6b69-4659-832c-72524340072f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
